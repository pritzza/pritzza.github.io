<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Panoramas</title>
    <link rel="stylesheet" href="styles.css">

    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>

<body>
    <div id="ambient-detail"></div>

    <header>
        <nav class="nav-links">
            <a href="#Images">Correspondences</a>
            <a href="#Homographies">Homographies</a>
            <a href="#Warping">Warping</a>
            <a href="#Rectification">Rectification</a>
            <a href="#Mosaics">Mosaics</a>
            <a href="#Automation">Automation</a>
        </nav>
    </header>

    <div id="container">
        <div id="header">
            <h1>Image Panoramas</h1>
            <p>By Jonathan Zakharov</p>
        </div>

        <div id="article">
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/5/cal_mosaic.png" alt="Cal Mosaic" height="450px"></a>
            </div>

            <h2>Introduction</h2>
            <p>
                This project focused on implementing perspective image warping and mosaicing to create panoramic images from multiple images. This was accomplished by computing the homographies between images, warping said images, and then blending them together into panoramas. Through this project, we gained practical experience with concepts in linear algebra, computational photography and computer vision, learning how to make our own panoramic images from scratch.
            </p>

            <h2 id="Images">Starting Images</h2>

            <h3>Implementation</h3>
            <p>
                To begin, we needed to go out and take photos such that we could compute the homographies between images in a set. A perspective transform or a homography relates two images when they have a shared center of projection. In practice this means taking photos of a scene from the same exact position, only changing the pitch and yaw along the axis of rotations of the camera.
            </p>
            <p>
                Here we capture some photos of Cal, the bay, and the cluttered desk I sit at now.
            </p>
            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/1/cal_l.png" alt="Left Image of Cal" width="300px">
                    <p class="caption">Left Image of Cal</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/1/cal_r.png" alt="Right Image of Cal" width="300px">
                    <p class="caption">Right Image of Cal</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/1/sf_l.png" alt="Left Image of San Francisco with Keypoints" width="300px">
                    <p class="caption">Left Image of San Francisco with Keypoints</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/1/sf_r.png" alt="Right Image of San Francisco with Keypoints" width="300px">
                    <p class="caption">Right Image of San Francisco with Keypoints</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/1/desk_l.png" alt="Left Desk Image with Triangulation" width="300px">
                    <p class="caption">Left Desk Image with Triangulation</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/1/desk_r.png" alt="Right Desk Image with Triangulation" width="300px">
                    <p class="caption">Right Desk Image with Triangulation</p>
                </div>
            </div>

            <h2 id="Homographies">Recovering Homographies</h2>

            <h3>Mathematical Foundation</h3>
            <p>
                A homography is a projective transformation that maps points from one plane to another. In the context of image processing, it allows us to relate two images of the same planar surface taken from different viewpoints. Mathematically, a homography $H$ is represented by a 3x3 matrix:
            </p>
            
            $$
                H = \begin{bmatrix}
                h_{11} & h_{12} & h_{13} \\
                h_{21} & h_{22} & h_{23} \\
                h_{31} & h_{32} & h_{33}
                \end{bmatrix}
            $$
            
            <p>
                This matrix has 9 elements, but because it is defined up to a scale factor, it effectively has 8 degrees of freedom.

                Given a point $(x, y)$ in the first image and its corresponding point $(x', y')$ in the second image, the homography relation can be expressed as:
            </p>
            
            $$
                \begin{bmatrix} wx' \\ wy' \\ w \end{bmatrix} = H \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}
            $$
                
            <p>
            </p>
            
                $$x' = \frac{h_{11}x + h_{12}y + h_{13}}{h_{31}x + h_{32}y + h_{33}}$$
            
                $$y' = \frac{h_{21}x + h_{22}y + h_{23}}{h_{31}x + h_{32}y + h_{33}}$$

            <h3>Linear System Setup</h3>
            <p>
                To solve for the homography matrix, we rearrange these equations into a linear system. For each point correspondence, we get two equations:
            </p>
            
                $$x'(h_{31}x + h_{32}y + h_{33}) = h_{11}x + h_{12}y + h_{13}$$
                $$y'(h_{31}x + h_{32}y + h_{33}) = h_{21}x + h_{22}y + h_{23}$$
            
            <p>
                These can be rewritten as:
            </p>
            
            $$
                \begin{bmatrix} 
                x & y & 1 & 0 & 0 & 0 & -xx' & -yx' & -x' \\
                0 & 0 & 0 & x & y & 1 & -xy' & -yy' & -y'
                \end{bmatrix} 
                \begin{bmatrix} h_{11} \\ h_{12} \\ h_{13} \\ h_{21} \\ h_{22} \\ h_{23} \\ h_{31} \\ h_{32} \\ h_{33} \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}
            $$
            
            <h3>Implementation</h3>
            <p>
                The <code>compute_homography</code> function in <code>warp_img.py</code> implements this process by setting up the system of linear equations $Ah = 0$, where $A$ is the matrix of coefficients from the equations above, and $h$ is the vector of homography matrix elements.
            </p>
            
            <p>
                With 4 point correspondences, we get 8 equations, which is sufficient to solve for the 8 degrees of freedom in the homography matrix. However, to improve robustness, we typically use more than 4 points and solve the overdetermined system using the least squares method.
                This is just a call to <code>np.linalg.lstsq</code>.
            </p>
    
            <h3>Results</h3>
            <p>
                We illustrate the effect of a perspective transform on a grid. The right image was create with the help of Photoshop's perspective warp tool. Applying the homography to the grid indeed gives us the same perspective transformed grid.
            </p>
            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/2/grid.png" alt="Original Grid" width="100%">
                    <p class="caption">Original Grid</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/2/persp_grid.png" alt="Perspective Transformed Grid" width="100%">
                    <p class="caption">Perspective Transformed Grid</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/2/grid_points.png" alt="Grid with Point Correspondences" width="100%">
                    <p class="caption">Grid with Point Correspondences</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/2/perp_grid_points.png" alt="Transformed Grid with Point Correspondences" width="100%">
                    <p class="caption">Transformed Grid with Point Correspondences</p>
                </div>
            </div>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/2/warped.png" alt="Warped Image Result" height="300px"></a>
                <p class="caption">Warped Image Result</p>
            </div>


            <h2 id="Warping">Image Warping</h2>
            <h3>Implementation</h3>
            <p>
                Once the homography is computed, we want to warp one image to align with another in the same image plane. The <code>warp_image</code> function in <code>warp_img.py</code> implements inverse warping for this purpose. It computes the inverse of the homography matrix and, for each pixel in the output image, calculates the corresponding location in the input image. To ensure all warped content is captured in the output image, we implement a helper method <code>compute_warped_image_bb</code> which calculates the bounding box and displacement of the warped image by transforming the corners of the original image.
            </p>

            <h3>Results</h3>
            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/3/caL_l_points.png" alt="Left Cal Image with Points" width="100%">
                    <p class="caption">Left Cal Image with Points</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/3/cal_r_points.png" alt="Right Cal Image with Points" width="100%">
                    <p class="caption">Right Cal Image with Points</p>
                </div>
            </div>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/3/cal_warped.png" alt="Warped Cal Image" height="300px"></a>
                <p class="caption">Warped Cal</p>
            </div>

            <h2 id="Rectification">Image Rectification</h2>
            <h3>Implementation</h3>
            <p>
                Image rectification serves as a benchmark for the success of our homography calculations and image warping implementations. Our <code>rectify_image</code> function in <code>rectify.py</code> demonstrates this process by taking an input image, a set of points defining a rectangular object in the image, and the desired dimensions of the rectified object. It computes a homography between these points and a predefined rectangular grid, then applies this homography to warp the entire image. This process effectively simulates rotating the camera to point directly at the planar surface, removing perspective distortion. Successful rectification results in an image where the selected object appears as a rectangle, verifying that our homography and warping functions work.
            </p>

            <h3>Results</h3>

            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/4/posted_points.png" alt="Poster Image with Points" width="200px">
                    <p class="caption">My Pikmin 2 Poster</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/4/poster_rectified.png" alt="Rectified Poster Image" width="200px">
                    <p class="caption">Rectified Pikmin 2 Poster</p>
                </div>

                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/4/insane_points.png" alt="Captcha Image with Points" width="200px">
                    <p class="caption">An Insane Captcha</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/4/insane_rectified.png" alt="Rectified Captcha Image" width="200px">
                    <p class="caption">Rectified Insane Captcha</p>
                </div>
            </div>

            <h2 id="Mosaics">Blending and Mosaic Creation</h2>
            <h3>Implementation</h3>
            <p>
                The ultimate goal of this project is to create panoramic images. With our successful implementation of image warping, the final step is to blend our warped images. The <code>blend_images</code> function in <code>mosaic.py</code> implements a simple blending technique. It creates a panorama canvas large enough to accommodate both images, places the second (unwarped) image onto the canvas, and then computes an average of the two images in the overlapping region.            </p>
            <p>
                The main function in <code>mosaic.py</code> outlines the overall mosaic creation process: first, it computes the homography between two images, then warps the first image to align with the second, and finally blends the warped image with the second image. While this approach produces a basic mosaic, it can result in some seams or ghosting artifacts when there are significant differences between images, like in lighting/exposure.
            </p>
            
            <h3>Results</h3>
            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/5/cal_left_pano.png" alt="Left Cal Panorama Image" width="100%">
                    <p class="caption">Left Cal Panorama Image</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/5/cal_right_pano.png" alt="Right Cal Panorama Image" width="100%">
                    <p class="caption">Right Cal Panorama Image</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/5/cal_left_mask.png" alt="Left Cal Mask" width="100%">
                    <p class="caption">Left Cal Mask</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/5/cal_right_mask.png" alt="Right Cal Mask" width="100%">
                    <p class="caption">Right Cal Mask</p>
                </div>
            </div>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/5/cal_mosaic.png" alt="Cal Mosaic Result" width="100%"></a>
                <p class="caption">Cal Mosaic</p>
            </div>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/5/sf_mosaic.png" alt="San Francisco Mosaic Result" width="100%"></a>
                <p class="caption">The Bay</p>
            </div>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/5/desk_mosaic.png" alt="Desk Mosaic Result" width="100%"></a>
                <p class="caption">My desk right now</p>
            </div>

        </div>

        <h2 id="Automation"></h2>
        <div id="header">
            <h1>Panorama Automation</h1>
        </div>
        <div id="article">
            <h2 id="Introduction2">Introduction</h2>
            <p>
                In the previous part of the project, we successfully automated the process of creating panoramic photos, given a set of images from the same center of projection with explicit specification of feature points in images and their correspondences between images. Our goal now is to create panoramic images without the need to explicitly specify points and their correspondences between images. In other words, we want to develop a system for automating the detection, matching, and transformation of key image features in images. Our procedure will look like this
            </p>
            <ul>
            <li>Detecting features in images.</li>
            <li>Extracting descriptors for detected features.</li>
            <li>Matching descriptors between images.</li>
            <li>Computing homographies with RANSAC.</li>
            <li>Mosaicing images into a panorama.</li>
            </ul>
            <p>
            The result is to fully automatically generate panorama photos given only the images to mosaic as input.
            </p>

            <h2 id="Mosaics">Feature Detection</h2>
            <h3>Implementation</h3>
            <p>
                Our goal in automatic image mosaicing is to automate the process of manually selecting correspondences between sets of images. To begin, we need to find feature points in an image that will have correspondences in other images we plan to mosaic together. Harris corner detection is a simple and effective way of identifying many high-interest regions or “corners” in each image that are likely to have corresponding points in other images.
            </p>
            <p>
                The Harris Corner Detector is well-suited for detecting corner features that remain consistent across images. Due to its robustness, it was chosen to automate the task of identifying points that would otherwise need to be manually selected as correspondences for image stitching. We used an existing implementation of Harris corner detection, which returns all detected corner points, giving us thousands of feature points on each image. The next step is to determine which features in one image have corresponding features in another.
            </p>
            <h3>Results</h3>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/6/Harris.png" alt="Desk Mosaic Result" width="600px"></a>
                <p class="caption">Harris Corner Detection</p>
            </div>
            <h2 id="Mosaics">Feaure Description Extraction</h2>
            <h3>Implementation</h3>
            <p>
                Now that we have a good set of candidate points throughout our images, we need a way to identify which features in one image correspond to features in another. We achieve this by performing feature descriptor extraction. For each detected feature, a feature descriptor is extracted from a 40x40 pixel patch centered on the feature. To make patches robust to noise and minor lighting changes, bias/gain normalization and Gaussian blur were applied, and patches were resized to an 8x8 array, reducing computational complexity without sacrificing uniqueness.
            </p>
            <h3>Results</h3>
            <p>Here are some 8x8 image patches extracted after extraction from Harris Corner Detection, lowpassed, normalized, and downscaled.</p>

            <div class="render-gallery3">

                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_0.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_1.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_2.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_3.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_4.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_6.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_7.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_8.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/patch_9.png" alt="Left Cal Panorama Image" width="50%">
                </div>
                
            </div>
            <h2 id="Mosaics">Feature Matching</h2>
            <h3>Implementation</h3>
            <p>
                With two images and their sets of image feature patches, we aim to determine which features in one image have matching features in another. This is achieved using a K-D Tree with the 2-Nearest Neighbors (2-NN) approach. Lowe’s ratio test was applied to ensure that matches are reliable by comparing the two nearest neighbors of each point and retaining only those with clear closest matches.
            </p>
            <p>
                We now have automatically generated matching points between images, identifying which points on multiple images correspond to each other. We’ve successfully automated the task of selecting matching points between images. Or have we?
            </p>
            <h3>Results</h3>
            <p>Here are some image feature correspondence pairs. Notice how the correspondnces aren't perfect to create some invariance to transformations.</p>

            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/matched_a_0.png" alt="Left Cal Panorama Image" width="50%">
                    <p class="caption">Image A Patch</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/matched_b_0.png" alt="Right Cal Panorama Image" width="50%">
                    <p class="caption">Image B Patch</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/matched_a_1.png" alt="Left Cal Mask" width="50%">
                    <p class="caption">Image A Patch</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/matched_b_1.png" alt="Right Cal Mask" width="50%">
                    <p class="caption">Image B Patch</p>
                </div>                
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/matched_a_2.png" alt="Left Cal Mask" width="50%">
                    <p class="caption">Image A Patch</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/matched_b_2.png" alt="Right Cal Mask" width="50%">
                    <p class="caption">Image B Patch</p>
                </div>
            </div>
            
            <p>Here we visualize the strongest correspondence found between the images at the base of The Campanile.</p>
            
            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/single_l.png" alt="Left Cal Panorama Image" width="100%">
                    <p class="caption">Left Image</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/single_r.png" alt="Right Cal Panorama Image" width="100%">
                    <p class="caption">Right Image</p>
                </div>
            </div>

            <p>Here are all of the correspondences between images, annotated by points of the same color. Notice the presence of false positive correspondences, but a majority cluster of true positives.</p>
            
            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/many_l.png" alt="Left Cal Mask" width="100%">
                    <p class="caption">All Left Image Correspondences</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/many_r.png" alt="Right Cal Mask" width="100%">
                    <p class="caption">All Right Image Correspondences</p>
                </div>
            </div>
            <h2 id="Mosaics">Homography Computation Using RANSAC</h2>
            <h3>Implementation</h3>
            <p>
                Feature matching performs well but may produce some false positives, resulting in outlier correspondences that reduce the accuracy of our least squares estimation when computing homographies between images. Our final step is to compute the homography using RANSAC, aligning matching points between images while detecting and removing outlier correspondences. This was achieved by iteratively selecting four random points to compute candidate homographies and evaluating the inliers based on a distance threshold. Of these candidate homographies, the one with the most inliers is used to compute the final homography using standard least squares.   
            </p>
            <h3>Results</h3>
            <p>
                We compare the results of our RANSAC-based homography estimation to the manual homography estimation. The differences are minimal, indicating that our RANSAC-based estimation is robust to outliers and produces a homography that is consistent with the manual estimation.
            </p>
            <div class="render-gallery">
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/manual_warp.png" alt="Left Cal Panorama Image" width="100%">
                    <p class="caption">Homography from manual points</p>
                </div>
                <div class="render-gallery-item">
                    <img src="../images/image-panoramas/6/auto_warp.png" alt="Right Cal Panorama Image" width="100%">
                    <p class="caption">Homography from RANSAC</p>
                </div>
            </div>

            <h2 id="Mosaics">Putting it all Together</h2>

            <p>
                Taking our algorithms for automatically computing homographies, we then warp and blend the images together as before, achieveing fully automated panorama creation. The results of this process are shown below and nearly indistinguishable from the manual process. Success!
            </p>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/7/cal_mosaic.png" alt="Cal Mosaic Result" width="100%"></a>
                <p class="caption">Cal Mosaic</p>
            </div>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/7/sf_mosaic.png" alt="San Francisco Mosaic Result" width="100%"></a>
                <p class="caption">The Bay</p>
            </div>
            <div class="single-image">
                <a href="#"><img src="../images/image-panoramas/7/desk_mosaic.png" alt="Desk Mosaic Result" width="100%"></a>
                <p class="caption">My desk right now</p>
            </div>

            <h2>Conclusion</h2>
            <p>
                Among the coolest things I've taken away from is RANSAC. Having not known about RANSAC before, I fint it is a fascinatingly robust and versatile statistical tool. I could see myself using it for many things. It was also really rewarding to be able to automate something which was laborious and not a straight forward/obvious computation.
            </p>
            <p>
                This project provided valuable hands-on experience with fundamental techniques in computational photography and computer vision. By implementing homography computation, image warping, basic blending, image feature detection, and image feature matching, we gained practical insight into the challenges and intricacies of creating panoramic images from multiple photographs.
            </p>
   
        </div>
    </div>
</body>

</html>